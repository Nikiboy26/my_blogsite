---
title: Specialty coffee grades
author: Nikita Kaymonov
date: '2022-01-02'
slug: []
categories:
  - R
tags: []
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Coffee quality prediction 

#### Introduction

Hi, I'm Nikita. I love high quality coffee. You probably have seen a lot of specialty cafes around (or probably sitting in one right now while reading this and drinking your Geisha coffee made in Chemex). For coffee to be put in the "specialty" category it has to be graded higher than 80 points on a 100 point scale. People who taste and grade coffee are trained specialists (like wine sommeliers) called q-graders. They can evaluate the quality and defects of green beans, find potential mistakes in coffee roasting and identify different roasts. I don't have highly developed sensory skills needed to be a grader. But I have other skills. So why not use machine learning to grade the coffee? 

Sounds interesting to you? Check out this analysis! 


```{r echo = F, message=FALSE}
library(tidyverse)
library(readr)
library(caret)
library(mlbench)
library(ranger)
library(assertive)

```

You can find the dataset [here](https://raw.githubusercontent.com/Nikiboy26/Coffee_quality_ML/main/Coffee%20Dataset.csv)


```{r echo = F, message=FALSE}
coffee <- read_csv("https://raw.githubusercontent.com/Nikiboy26/Coffee_quality_ML/main/Coffee%20Dataset.csv") %>%
  rename_all(tolower) #I like when there's consistency with names, makes analysis easier

#Rename first column
coffee<-coffee%>%
  rename("id" = "...1")
```


```{r include = F}
coffee_sub <- coffee%>%
  select(id, owner, country.of.origin, farm.name, mill, company, region, harvest.year, 
         producer, variety, processing.method, category.one.defects, 
         quakers, category.two.defects, altitude_mean_meters, total.cup.points)

coffee_sub$country.of.origin <- str_replace_all(coffee_sub$country.of.origin, 'Tanzania, United Republic Of', 'Tanzania')
```

#### Country of origin 

We have a lot of countries, let's see what are the most popular countries of origin

```{r echo = F}
head(coffee_sub%>%
  count(country.of.origin)%>%
  arrange(desc(n)), 8)%>%
  ggplot(aes(x = n, y = reorder(country.of.origin, n))) + geom_bar(stat = "identity", fill = "#0072B2") + 
  labs(x = "Country", y = "Coffee") + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
                                          panel.background = element_blank(), axis.line = element_line(colour = "black")) 
```

Here we see that a lot of coffee in this dataset comes from Americas 

```{r include = F}
countries <- head(coffee_sub%>% 
  count(country.of.origin)%>%
  arrange(n), 14) #Create a vector with 14 rarest countries in dataset

coffee_sub <- coffee_sub%>%
  filter(!country.of.origin %in% c(countries$country.of.origin)) #Remove these countries

#See countries with lowest amount of coffee now 
head(coffee_sub%>%
       count(country.of.origin)%>%
       arrange(n), 10)%>%
  ggplot(aes(x = n, y = reorder(country.of.origin,n))) + geom_bar(stat = "identity", fill = "#0072B2") + labs(x = "Country", y = "Coffee") + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
                                          panel.background = element_blank(), axis.line = element_line(colour = "black"))
  
```


```{r include= F}
coffee_sub%>% 
  summarise_all(n_distinct)
```


```{r include = F}
coffee_sub <- coffee_sub%>%
  select(-c(owner, farm.name, mill, region, producer, company))
```



```{r include = F}
unique(coffee_sub$harvest.year) #Get unique year values
```

```{r include = F}
coffee_sub$harvest.year <- str_replace_all(coffee_sub$harvest.year, "08/09 crop", "2008")
coffee_sub$harvest.year <- str_replace_all(coffee_sub$harvest.year, "4T/10", "2010")

#Get first year in two years formar
coffee_sub$harvest.year <- as.numeric(str_extract(coffee_sub$harvest.year, pattern = "20[0-1][0-9]"))
```

```{r include = F}
coffee_sub <- coffee_sub%>% na.omit()
```

```{r include = F}
coffee_sub$altitude_mean_meters <- str_replace_all(coffee_sub$altitude_mean_meters, "110000", "1100")
coffee_sub$altitude_mean_meters <- str_replace_all(coffee_sub$altitude_mean_meters, "11000", "1100")
coffee_sub$altitude_mean_meters <- str_replace_all(coffee_sub$altitude_mean_meters, "190164", "1901")
#Looks like there was a mistake while reporting data for Guatemala coffee and somebody missed a decimal. The same with Nicaragua coffee. 
```

```{r include = F}
assert_all_are_in_closed_range(coffee_sub$altitude_mean_meters, lower = 0, upper = 5000)
#Let's make sure everything is within a range. 
```

#### Proccessing methods 

```{r echo = F}
coffee_sub%>%
  count(processing.method)%>%
  ggplot(aes(x = reorder(processing.method,-n), y = n)) + 
  geom_col(fill = "#0072B2") + labs(x = 'Process Method', y = 'Number') + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
                                          panel.background = element_blank(), axis.line = element_line(colour = "black"))
```

Most of the coffee in the dataset is processed using washing method. Which can be explained by the most popular countries our coffee comes from. Dry method is more common in countries like Ethiopia or Brazil where the water is expensive so they just leave beans in the sun right after picking. 


```{r echo = F}
coffee_sub$country.of.origin <- str_replace_all(coffee_sub$country.of.origin, 'Tanzania, United Republic Of', 'Tanzania')

#Process Methods
coffee_sub%>%
  filter(country.of.origin %in% c(coffee_sub%>%
                                    count(country.of.origin)%>%
                                    filter(n >25)%>%
                                    pull(country.of.origin)))%>%
  filter(processing.method %in% c('Washed / Wet', 'Natural / Dry'))%>%
  count(country.of.origin, processing.method)%>%
  mutate(country = factor(country.of.origin, levels = c("Mexico", "Guatemala", "Colombia", "Brazil", 
                                                        "Taiwan", "Honduras", "Costa Rica", "Tanzania",
                                                        "Uganda")))%>%
  ggplot(aes(x = country, y = n, fill = reorder(processing.method,-n))) + geom_col() +
  labs(x = 'Number of Coffee',
       y = 'Country', fill = 'Process Method') + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
                                                       panel.background = element_blank(), axis.line = element_line(colour = "black")) + 
  scale_fill_manual(values=c("azure3","#0072B2")) 



```

Here Brazil is the only country where dry processing methods is more common. As we mentioned before it often happens in regions with limited access to water and Brazil is one of these regions. Although it can have a lot of advantages when we talk about the taste.  Dried coffee tends to have a rich and heavy body, which many coffee drinkers prefer. Also it allows to experiment with different fermentation techniques. 

#### Coffee quality 

Not all coffee tastes the same. And some beans are better than others. After graders taste the beans they assign grades to it. The widely accepted definition of specialty coffee is coffee scoring 80 points or above on a 100-point scale. Coffee scoring from 90â€“100 is graded Outstanding, coffee that scores 85â€“89.99 is graded Excellent, while coffee scoring 80â€“84.99 is graded Very Good. Everything lower than that doesn't fall into "Specialty' category.

```{r echo = F}
coffee_sub <- coffee_sub%>%
 mutate(grade = case_when(
   total.cup.points >= 85 ~ 'Excellent',
   total.cup.points >= 80 ~ 'Very Good',
   total.cup.points < 80 ~ 'Not Special'
 ))

coffee_sub$grade <- factor(coffee_sub$grade, levels = c('Not Special', 'Very Good', 'Excellent'))

coffee_sub%>%
  filter(country.of.origin %in% c(coffee_sub%>%
                                    count(country.of.origin)%>%
                                    filter(n >25)%>%
                                    pull(country.of.origin)))%>%
  count(country.of.origin, grade)%>%
  mutate(country = factor(country.of.origin, levels = c("Mexico", "Guatemala", "Colombia", "Brazil", 
                                                        "Taiwan", "Honduras", "Costa Rica", "Tanzania",
                                                        "Uganda")))%>%
  ggplot(aes(x = country, y = n, fill = grade)) + geom_col() + 
  scale_fill_manual(values=c("azure3","#0072B2", 'darkorange')) +  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))
```

The highest grading point we have in this dataset is 89.92. Which means we don't really have bags with 'outstanding' coffee. There are some "excellent" coffees but most bags fall into 'Very Good' category. Which means only 13.5% of our coffee is not 'Specialty Coffee'.
So if you would randomly pick a bag from our dataset most likely you will enjoy your cup of coffee (assuming you know how to brew it). 

#### Modelling 

As I showed above coffee comes from different countries and processed using different methods. There are also other variables like the altitude where coffee grows, different type of defects beans have etc. 
To sell our beans to good cafes we need to find a trained person who would taste our coffee and assign the grade. Instead of training a person we can just train a machine and then using it to assign grades to new coffee. 
So below you'll find my model that does exactly this. 


### Building predictive models

#### Test/train split 

Let's start with splitting data into test and train sets, so we don't predict on the same data we used for training and our model is actually good for predicting. 

```{r}
coffee_sub <- coffee_sub%>%
  select(-id)

set.seed(150)
rows <- sample(nrow(coffee_sub))

# Randomly order data
shuffled_coffee <- coffee_sub[rows,]

# Determine row to split on: split
split <- round(nrow(coffee_sub) * .80)

# Create train
train <- shuffled_coffee[1:split,]

# Create test
test <- shuffled_coffee[(split +1):nrow(shuffled_coffee),]
```

#### Cross validation model 

Let's try lm model with cross validation. It's a good start. 

```{r echo = T, message=FALSE, results='hide', warning=FALSE}
set.seed(66)
# Fit lm model using 10-fold CV: model
model_cv <- train(
  total.cup.points ~., 
  coffee_sub,
  method = "lm",
  trControl = trainControl(
    method = "cv", 
    number = 10,
    verboseIter = TRUE
  )
)

p <- predict(model_cv, test)
```

To evaluate a regression model I like to use RMSE(root mean square error). The smaller here is better. 

```{r}
error <- p - test[,"total.cup.points"]

rmse_cv <-  sqrt(mean(error$total.cup.points^2)) #SD = 1.722239
rmse_cv
```

Good start, but we want RMSE that less than standart deviation in dataset, so let's try Random Forest 

#### Random forest 

```{r echo = T, message=FALSE, results='hide', warning=FALSE}
set.seed(60)
model_rf <- train(
  total.cup.points ~.,
  tuneLength = 1,
  data = coffee_sub, 
  method = "ranger",
  trControl = trainControl(
    method = "cv", 
    number = 5, 
    verboseIter = TRUE
  )
)

p <- predict(model_rf, test)
```

And calculate RMSE

```{r}
error <- p - test[,"total.cup.points"]

# Calculate RMSE
rmse_rf <-  sqrt(mean(error$total.cup.points^2)) # 
rmse_rf
```

So we got RMSE 1.261236 which is pretty good result given SD = 2.610294. Since hiring q-graders can be expensive, some coffee farmers can actually use machine learning for grading their coffee. 

##### Next step 

Having some newer data and wrapping this model into Shiny app and you can just input the info on whatever beans you have and get pretty qccurade grades ðŸ™‚


